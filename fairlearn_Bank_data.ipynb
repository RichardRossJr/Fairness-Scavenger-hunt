{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fairlearn_Bank_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardRossJr/Fairness-Scavenger-hunt/blob/main/fairlearn_Bank_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKBLCUKOavg"
      },
      "source": [
        "#Fairness AI Microsoft\n",
        "###Grace Nelson\n",
        "5/2/2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1XwT7O7MBdd"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uORIr2isM085",
        "outputId": "d11894bd-57f2-46c9-85e3-f13e96e02907"
      },
      "source": [
        "pip install raiwidgets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting raiwidgets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/8d/d14713e521fbce3bd1fa95f83a6c882fcfe20ace2ee2a97b6718a59aaea8/raiwidgets-0.4.0-py3-none-any.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 22.7MB/s \n",
            "\u001b[?25hCollecting rai-core-flask==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/81/a13432b11c3daaee8fa36f2857d7db6d80a85baf5b059f241be0f03d9dd7/rai_core_flask-0.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from raiwidgets) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from raiwidgets) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from raiwidgets) (0.22.2.post1)\n",
            "Requirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.7/dist-packages (from raiwidgets) (2.2.3)\n",
            "Collecting erroranalysis>=0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/1f/bbdd15cc1743a3aea881f32d5f01b29e1866639b70af14593edb3904f359/erroranalysis-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from raiwidgets) (1.1.5)\n",
            "Collecting jinja2==2.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/24/4f35961e5c669e96f6559760042a55b9bcfcdb82b9bdb3c8753dbe042e35/Jinja2-2.11.1-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 43.9MB/s \n",
            "\u001b[?25hCollecting ipython==7.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/6a/210816c943c9aeeb29e4e18a298f14bf0e118fe222a23e13bfcc2d41b0a4/ipython-7.16.1-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 38.3MB/s \n",
            "\u001b[?25hCollecting greenlet==0.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/34/2c4ea49f9d41aaf664f72abb10880a56d3560398b74b3936055579188836/greenlet-0.4.17-cp37-cp37m-manylinux1_x86_64.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hCollecting gevent==20.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/a0/acbe4aecc341cc38641e82e2c12497f9ff4b621730e40c0c0411ad867a90/gevent-20.9.0-cp37-cp37m-manylinux2010_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 43.5MB/s \n",
            "\u001b[?25hCollecting Flask-Cors==3.0.9\n",
            "  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Flask==1.1.2 in /usr/local/lib/python3.7/dist-packages (from rai-core-flask==0.2.2->raiwidgets) (1.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->raiwidgets) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->raiwidgets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->raiwidgets) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2==2.11.1->raiwidgets) (2.0.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (56.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (5.0.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e6/4b4ca4fa94462d4560ba2f4e62e62108ab07be2e16a92e594e43b12d3300/prompt_toolkit-3.0.18-py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->raiwidgets) (0.18.0)\n",
            "Collecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors==3.0.9->rai-core-flask==0.2.2->raiwidgets) (1.15.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.2->rai-core-flask==0.2.2->raiwidgets) (2.0.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.2->rai-core-flask==0.2.2->raiwidgets) (2.0.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.2->rai-core-flask==0.2.2->raiwidgets) (8.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython==7.16.1->raiwidgets) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.16.1->raiwidgets) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.16.1->raiwidgets) (0.7.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.16.1->raiwidgets) (0.8.2)\n",
            "\u001b[31mERROR: sqlalchemy 1.4.15 has requirement greenlet!=0.4.17; python_version >= \"3\", but you'll have greenlet 0.4.17 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: greenlet, zope.event, zope.interface, gevent, Flask-Cors, prompt-toolkit, ipython, rai-core-flask, erroranalysis, jinja2, raiwidgets\n",
            "  Found existing installation: greenlet 1.1.0\n",
            "    Uninstalling greenlet-1.1.0:\n",
            "      Successfully uninstalled greenlet-1.1.0\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "Successfully installed Flask-Cors-3.0.9 erroranalysis-0.1.3 gevent-20.9.0 greenlet-0.4.17 ipython-7.16.1 jinja2-2.11.1 prompt-toolkit-3.0.18 rai-core-flask-0.2.2 raiwidgets-0.4.0 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APFeIp90gzlO",
        "outputId": "22669e31-edbd-49b6-c787-d6ad5e2d08bf"
      },
      "source": [
        "pip install fairlearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/a4/87a3ee19c036860a0b04dc5c9d51c86b0e147a379981f05fec0b34f8cdfc/fairlearn-0.6.2-py3-none-any.whl (24.6MB)\n",
            "\u001b[K     |████████████████████████████████| 24.6MB 120kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyitsvOKMBdf"
      },
      "source": [
        "Fairlearn with Bank Marketing Data\n",
        "===========================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIg0xcBfMBdg"
      },
      "source": [
        "This notebook shows how to use Fairlearn and the Fairness dashboard to\n",
        "generate predictors for the Bank Marketing dataset. This dataset is a\n",
        "classification problem - to predict if the client will subscribe (yes/no) a term deposit\n",
        "\n",
        "We will first train a fairness-unaware predictor and show that it leads\n",
        "to unfair decisions under a specific notion of fairness called\n",
        "*demographic parity*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZS26beMBdg"
      },
      "source": [
        "Load and preprocess the data set\n",
        "================================\n",
        "\n",
        "We download the data set using fetch\\_adult function in\n",
        "fairlearn.datasets. We start by importing the various modules we're\n",
        "going to use:\n",
        "\n",
        "> **note**\n",
        ">\n",
        "> The `FairlearnDashboard`{.sourceCode} is no longer being developed as\n",
        "> part of Fairlearn. The widget itself has been moved to [the raiwidgets\n",
        "> package](https://pypi.org/project/raiwidgets/). Fairlearn will provide\n",
        "> some of the existing functionality through\n",
        "> `matplotlib`{.sourceCode}-based visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaHq_s5IMBdh"
      },
      "source": [
        "# from fairlearn.widget import FairlearnDashboard\n",
        "from raiwidgets import FairnessDashboard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fairlearn.reductions import GridSearch\n",
        "from fairlearn.reductions import DemographicParity, ErrorRate\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQvm8d7zMBdh"
      },
      "source": [
        "We can now load and inspect the data by using the fairlearn.datasets\n",
        "module:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8ZguqMIM1D0"
      },
      "source": [
        "# Data Labels for the Dataset\n",
        "1 - age (numeric)\n",
        "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "\n",
        "related with the last contact of the current campaign:\n",
        "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
        "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "\n",
        "other attributes:\n",
        "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "\n",
        "social and economic context attributes\n",
        "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
        "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
        "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
        "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
        "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
        "\n",
        "Output variable (desired target):\n",
        "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "n6Wj0R51MBdi",
        "outputId": "98d65222-3e86-48c6-befa-f3532c071abd"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "\n",
        "data = fetch_openml(data_id=1461, as_frame=True)\n",
        "X_raw = data.data\n",
        "Y = (data.target)\n",
        "X_raw"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c13219b48306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1461\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \"data_id.\")\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0mdata_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_data_description_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"active\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         warn(\"Version {} of dataset {} is inactive, meaning that issues have \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_data_description_by_id\u001b[0;34m(data_id, data_home)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Dataset with data_id {} not found.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     json_data = _get_json_content_from_openml_api(url, error_message, True,\n\u001b[0;32m--> 398\u001b[0;31m                                                   data_home)\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_set_description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_json_content_from_openml_api\u001b[0;34m(url, error_message, raise_if_error, data_home)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# 412 error, not in except for nicer traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mraise_if_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dataset with data_id 1461 not found."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBnJMgY6MBdi"
      },
      "source": [
        "We are going to treat the Level of Education of each individual as a sensitive feature and in this particular\n",
        "case we are going separate this feature out and drop it from the main\n",
        "data. We then perform some standard data preprocessing steps to convert\n",
        "the data into a format suitable for the ML algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlibPzeSMbT-"
      },
      "source": [
        "Here we are treating level of education as sensitve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrifxDVtMBdi"
      },
      "source": [
        "A = X_raw[\"V4\"]\n",
        "X = X_raw.drop(labels=['V4'], axis=1)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_0Mkkh2J6Gs"
      },
      "source": [
        "X_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkQn5dAxMBdj"
      },
      "source": [
        "Finally, we split the data into training and test sets:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utgru2j6MBdj"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X_scaled,\n",
        "                                                                     Y,\n",
        "                                                                     A,\n",
        "                                                                     test_size=0.2,\n",
        "                                                                     random_state=0,\n",
        "                                                                     stratify=Y)\n",
        "\n",
        "# Work around indexing bug\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "A_train = A_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "A_test = A_test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Yi9iqMBdj"
      },
      "source": [
        "Training a fairness-unaware predictor\n",
        "=====================================\n",
        "\n",
        "To show the effect of Fairlearn we will first train a standard ML\n",
        "predictor that does not incorporate fairness. For speed of\n",
        "demonstration, we use the simple\n",
        "sklearn.linear\\_model.LogisticRegression class:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUP8u83MBdk"
      },
      "source": [
        "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
        "\n",
        "unmitigated_predictor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QssCR8KaMBdk"
      },
      "source": [
        "We can load this predictor into the Fairness dashboard, and assess its\n",
        "fairness:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzcCpZqaMBdk"
      },
      "source": [
        "y_pred = unmitigated_predictor.predict(X_test)\n",
        "FairnessDashboard(sensitive_features=A_test,\n",
        "                   y_true=Y_test,\n",
        "                    y_pred = y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWdjo4sPMBdk"
      },
      "source": [
        "#Performance Metric: Accuracy\n",
        "#Fairness Metric #1: Demographic Parity Difference\n",
        "3.37% (The maximum difference in selection rate, that is the fraction with the predicted label 1, between any two groups)\n",
        "This means that there is at max a 3% difference in selection between the different levels of education, we want the difference to be 0 and 3.37% is pretty close. This means that there is not much of a difference in terms of pure selection rates between the education levels\n",
        "\n",
        "#Fairness Metric #2: Demographic Parity Ratio\n",
        "57.6% (the minimum ratio of selection rates, that is the fraction with)\n",
        "The demographic parity ratio is at the minimin 57% whihc means that at minimum some education levels are selected to be successes twice as much as others, Specifcially unknown and tertary are selected twice as much as primary and secondary.\n",
        "\n",
        "#Fairness Metric #3: Error Rate Difference\n",
        "5.61% (the maximum difference between the error rates of any two groups)\n",
        "in terms of error rate we can see that at max difference in arror rates of any of the educations levels if 5%, this is rather small so we can see in terms of error rate all education level peform relatively close to eachother.\n",
        "\n",
        "#Fairness Metric #4: Minimum F-1 Score\n",
        "42.2% (F1-score is the harmonic mean of precision and recall, The minimum F1-score of all groups.)\n",
        "We want F-1 to be close to 1 since it is the ratio of precision and recall (ratios of ppostives and negative) a score of 1 shows our model is very accurate. Since this model's score is at a minimum .42 and .42 is closer to Zero than one we can see that this model is less than mediocre at worst. \n",
        "\n",
        "#Selection Rate\n",
        "Looking at the difference in both selection and false postive and false negative rate we can see that people with unknown or tertiary education are selected at almost twice the rate of those with just primary or secondary education. This means that they are marked as successful at twice the rate. \n",
        "\n"
      ]
    }
  ]
}